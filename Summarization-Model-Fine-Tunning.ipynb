{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T18:11:57.971207Z",
     "iopub.status.busy": "2025-04-12T18:11:57.970810Z",
     "iopub.status.idle": "2025-04-12T18:55:18.414181Z",
     "shell.execute_reply": "2025-04-12T18:55:18.412956Z",
     "shell.execute_reply.started": "2025-04-12T18:11:57.971171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2165840f3b4f4a428ab370534a065368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76daba7e0ed04c2c95fe1faf03b3498b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8702600c365c4f4d93d720017d5c9d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75279a10a7e0482890c5927d81c5eca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c7ee3b98c405ab30c785e83f795d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c044a0a39cd406abefb0eb49ac1c386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339136d6c77d48c6bf9e8b71a35225a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5376' max='5376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5376/5376 42:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.558300</td>\n",
       "      <td>0.574562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.361400</td>\n",
       "      <td>0.513873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Destination path '/kaggle/working/t5_summary_model/checkpoint-5376' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4496daa62709>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Save final checkpoint as main model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mfinal_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_path}/checkpoint-{trainer.state.global_step}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Optional: Convert model to FP16 (if space matters and your device supports it)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Destination path '/kaggle/working/t5_summary_model/checkpoint-5376' already exists"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Load JSON dataset\n",
    "with open(\"/kaggle/input/notes-explanation-and-summarization-dataset/Notes Explanation and Summarization Preprocessed Dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to input-output pairs: explanation â†’ summary\n",
    "formatted_data = [{\"input_text\": \"summarize: \" + d[\"explanation\"], \"target_text\": d[\"summary\"]} for d in data]\n",
    "\n",
    "# Split into training and evaluation\n",
    "train_data, eval_data = train_test_split(formatted_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Hugging Face DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_data),\n",
    "    \"eval\": Dataset.from_list(eval_data)\n",
    "})\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    labels = tokenizer(examples[\"target_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-large\")\n",
    "\n",
    "# Path to save model\n",
    "model_path = \"/kaggle/working/t5_summary_model\"\n",
    "\n",
    "# Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "model.save_pretrained(model_path, safe_serialization=True)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "# Optional: Remove unnecessary files (if they exist)\n",
    "shutil.rmtree(f\"{model_path}/checkpoint-*/optimizer.pt\", ignore_errors=True)\n",
    "shutil.rmtree(f\"{model_path}/checkpoint-*/scheduler.pt\", ignore_errors=True)\n",
    "shutil.rmtree(f\"{model_path}/checkpoint-*/rng_state.pth\", ignore_errors=True)\n",
    "\n",
    "# Save final checkpoint as main model\n",
    "final_checkpoint = f\"{model_path}/checkpoint-{trainer.state.global_step}\"\n",
    "shutil.move(final_checkpoint, model_path)\n",
    "\n",
    "# Optional: Convert model to FP16 (if space matters and your device supports it)\n",
    "model.half()\n",
    "model.save_pretrained(model_path, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:04:11.245959Z",
     "iopub.status.busy": "2025-04-12T19:04:11.245643Z",
     "iopub.status.idle": "2025-04-12T19:06:42.509834Z",
     "shell.execute_reply": "2025-04-12T19:06:42.508843Z",
     "shell.execute_reply.started": "2025-04-12T19:04:11.245936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/t5_summary_model/ (stored 0%)\n",
      "  adding: kaggle/working/t5_summary_model/generation_config.json (deflated 29%)\n",
      "  adding: kaggle/working/t5_summary_model/model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/t5_summary_model/tokenizer_config.json (deflated 94%)\n",
      "  adding: kaggle/working/t5_summary_model/spiece.model (deflated 48%)\n",
      "  adding: kaggle/working/t5_summary_model/special_tokens_map.json (deflated 85%)\n",
      "  adding: kaggle/working/t5_summary_model/config.json (deflated 62%)\n",
      "Model saved and zipped for download!\n"
     ]
    }
   ],
   "source": [
    "# Convert to ZIP for download\n",
    "!zip -r summary_model.zip /kaggle/working/t5_summary_model\n",
    "print(\"Model saved and zipped for download!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T19:07:10.772528Z",
     "iopub.status.busy": "2025-04-12T19:07:10.772156Z",
     "iopub.status.idle": "2025-04-12T19:07:10.778387Z",
     "shell.execute_reply": "2025-04-12T19:07:10.777576Z",
     "shell.execute_reply.started": "2025-04-12T19:07:10.772480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='summary_model.zip' target='_blank'>summary_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/summary_model.zip"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r\"summary_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 1 ---\n",
      "Generated: In summary, an Operating System is a crucial software component that manages the resources and interactions between the hardware and software components of a computer system. It provides abstraction, resource allocation, resource protection, and fault tolerance, allowing programs to interact with the hardware without knowing the underlying details. By understanding the key principles and functions of an OS, you can appreciate the importance of this critical component in modern computing.\n",
      "Reference: In summary, an Operating System performs three main functions: process management, memory management, and I/O management. It provides abstraction, resource allocation, resource protection, and fault tolerance to ensure the efficient and reliable operation of computer systems. By understanding what operating systems do, we can appreciate the critical role they play in facilitating our interactions with computers and enabling us to accomplish tasks efficiently and effectively.\n",
      "BLEU Score: 0.2060\n",
      "ROUGE-1 F1: 0.5147\n",
      "ROUGE-2 F1: 0.2687\n",
      "ROUGE-L F1: 0.3971\n",
      "\n",
      "--- Example 2 ---\n",
      "Generated: Computer-System Organization is the design and organization of a computer system, comprising hardware, operating system, and application software components. The key principles of modularity, hierarchy, communication, and abstraction enable the system to efficiently process information, manage resources, and provide reliable services. By understanding these principles and designing a well-structured system, we can better appreciate the complexity and beauty of modern computing systems.\n",
      "Reference: Computer-System Organization is the design and structure of a computer system, comprising hardware, operating system, and application software components. The key principles of modularity, hierarchy, communication, and abstraction enable the system to efficiently process information, manage resources, and provide reliable services. By understanding the organization of a computer system, we can better appreciate the complexity and interconnectedness of its components, and design more effective and efficient systems.\n",
      "BLEU Score: 0.7208\n",
      "ROUGE-1 F1: 0.8939\n",
      "ROUGE-2 F1: 0.7846\n",
      "ROUGE-L F1: 0.8182\n",
      "\n",
      "--- Example 3 ---\n",
      "Generated: Computer-System Architecture is the design and organization of the components that make up a computer system. The key principles of modularity, scalability, flexibility, reliability, performance, and security are essential in creating a system that can effectively execute tasks, processes, or applications while minimizing resource, errors, and costs. By understanding these principles and designing a well-structured architecture, computer-system architects can create efficient, reliable, and scalable systems that meet the needs of users and organizations.\n",
      "Reference: Computer-System Architecture is the design and organization of the components that make up a computer system, focusing on modularity, scalability, flexibility, reliability, performance, and security. By understanding these key principles and designing a system that balances these factors, computer-system architects can create efficient, reliable, and scalable systems that meet the needs of users and organizations.\n",
      "BLEU Score: 0.5405\n",
      "ROUGE-1 F1: 0.7820\n",
      "ROUGE-2 F1: 0.7176\n",
      "ROUGE-L F1: 0.7368\n",
      "\n",
      "--- Example 4 ---\n",
      "Generated: Operating-system operations are the fundamental mechanisms by which an OS manages the interaction between a computer's hardware and software resources, ensuring efficient and secure use of system resources. Key principles include process management, memory management, file system management, I/O management, security, interrupt handling, and error handling. By understanding these principles and mechanisms, you can appreciate the importance of operating systems in modern computing.\n",
      "Reference: In summary, operating-system operations involve the management of processes, memory, file systems, I/O operations, security, interrupt handling, and error handling. These mechanisms work together to ensure efficient and secure use of system resources, allowing applications to run smoothly and interact with users. By understanding these principles and mechanisms, developers can design and build more robust and reliable operating systems that provide a better user experience.\n",
      "BLEU Score: 0.2377\n",
      "ROUGE-1 F1: 0.6015\n",
      "ROUGE-2 F1: 0.3359\n",
      "ROUGE-L F1: 0.4060\n",
      "\n",
      "--- Example 5 ---\n",
      "Generated: Resource Management is the process of planning, organizing, and controlling the acquisition, allocation, and utilization of resources to achieve specific goals and objectives. The key principles of resource management include resource availability, resource allocation, resource utilization, resource optimization, and resource flexibility. By following these principles, organizations can ensure that resources are used effectively, projects are completed on time, and maintain a high level of quality.\n",
      "Reference: Resource Management is a critical process that involves planning, organizing, and controlling the acquisition, allocation, and utilization of resources to achieve specific goals and objectives. The key principles of Resource Management include Resource Availability, Resource Allocation, Resource Utilization, Resource Optimization, and Resource Flexibility. By following these principles, organizations can ensure that resources are used effectively and efficiently, leading to improved performance, productivity, and overall success.\n",
      "BLEU Score: 0.4937\n",
      "ROUGE-1 F1: 0.8154\n",
      "ROUGE-2 F1: 0.7500\n",
      "ROUGE-L F1: 0.8000\n",
      "\n",
      "==== AVERAGE METRICS ====\n",
      "Average BLEU Score: 0.4397\n",
      "Average ROUGE-1 F1: 0.7215\n",
      "Average ROUGE-2 F1: 0.5713\n",
      "Average ROUGE-L F1: 0.6316\n"
     ]
    }
   ],
   "source": [
    "# Load a few samples from the dataset\n",
    "with open(\"Notes Explanation and Summarization Preprocessed Dataset.json\", \"r\") as f:\n",
    "    data = json.load(f)[:5]  # Just first 5 samples\n",
    "\n",
    "# Load fine-tuned model and tokenizer\n",
    "model_path = \"t5_summary_model\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Init metrics\n",
    "smoothing_fn = SmoothingFunction().method4\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "bleu_scores = []\n",
    "rouge1_f1s = []\n",
    "rouge2_f1s = []\n",
    "rougeL_f1s = []\n",
    "\n",
    "# Evaluate\n",
    "for i, item in enumerate(data):\n",
    "    input_text = \"summarize: \" + item[\"explanation\"]\n",
    "    reference = item[\"summary\"]\n",
    "\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    summary_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=512,\n",
    "        num_beams=8,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # BLEU\n",
    "    ref_tokens = [reference.split()]\n",
    "    gen_tokens = generated_summary.split()\n",
    "    bleu = sentence_bleu(ref_tokens, gen_tokens, smoothing_function=smoothing_fn)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = scorer.score(reference, generated_summary)\n",
    "    rouge1_f1s.append(rouge['rouge1'].fmeasure)\n",
    "    rouge2_f1s.append(rouge['rouge2'].fmeasure)\n",
    "    rougeL_f1s.append(rouge['rougeL'].fmeasure)\n",
    "\n",
    "    # Print\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(f\"Generated: {generated_summary}\")\n",
    "    print(f\"Reference: {reference}\")\n",
    "    print(f\"BLEU Score: {bleu:.4f}\")\n",
    "    print(f\"ROUGE-1 F1: {rouge['rouge1'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-2 F1: {rouge['rouge2'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-L F1: {rouge['rougeL'].fmeasure:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Averages\n",
    "print(\"==== AVERAGE METRICS ====\")\n",
    "print(f\"Average BLEU Score: {sum(bleu_scores)/len(bleu_scores):.4f}\")\n",
    "print(f\"Average ROUGE-1 F1: {sum(rouge1_f1s)/len(rouge1_f1s):.4f}\")\n",
    "print(f\"Average ROUGE-2 F1: {sum(rouge2_f1s)/len(rouge2_f1s):.4f}\")\n",
    "print(f\"Average ROUGE-L F1: {sum(rougeL_f1s)/len(rougeL_f1s):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BLEU\t0.4397\tModerate lexical overlap â€” good, but BLEU is stricter and can penalize paraphrasing.\n",
    "* ROUGE-1 F1\t0.7215\tStrong unigram overlap â€” the model captures key concepts very well.\n",
    "* ROUGE-2 F1\t0.5713\tGood phrase-level fluency â€” summaries are fairly well-phrased.\n",
    "* ROUGE-L F1\t0.6316\tDecent structure/order similarity â€” model preserves logical flow."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7012298,
     "sourceId": 11227086,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
